{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8LvFTsV_9We0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "FyAdeRVa-mKr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "FA2rJwMb-DwD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "KELc_7jY-bLL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = train_dataset.data.shape[1], train_dataset.data.shape[2]\n",
        "num_channels = 1 # Grayscale\n"
      ],
      "metadata": {
        "id": "BCyHe5xx-dhD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim=2):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.encoder_conv = nn.Sequential(\n",
        "            # Input (N, 1, 28, 28)\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # -> (N, 64, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten() # -> (N, 64 * 14 * 14) = (N, 12544)\n",
        "        )\n",
        "\n",
        "        self.conv_shape = (64, 14, 14)\n",
        "\n",
        "\n",
        "        self.encoder_dense = nn.Sequential(\n",
        "            nn.Linear(self.conv_shape[0] * self.conv_shape[1] * self.conv_shape[2], 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_mu = nn.Linear(32, latent_dim)\n",
        "        self.fc_log_var = nn.Linear(32, latent_dim)\n",
        "        self.decoder_dense = nn.Sequential(\n",
        "            nn.Linear(latent_dim, self.conv_shape[0] * self.conv_shape[1] * self.conv_shape[2]),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.Unflatten(1, self.conv_shape),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1), # -> (N, 32, 28, 28)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, num_channels, kernel_size=3, padding=1), # -> (N, 1, 28, 28)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.encoder_conv(x)\n",
        "        x = self.encoder_dense(x)\n",
        "        mu = self.fc_mu(x)\n",
        "        log_var = self.fc_log_var(x)\n",
        "\n",
        "        # Reparameterization\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "\n",
        "        # Decoder path\n",
        "        x_recon = self.decoder_dense(z)\n",
        "        x_recon = self.decoder_conv(x_recon)\n",
        "\n",
        "        return x_recon, mu, log_var\n"
      ],
      "metadata": {
        "id": "VYU0eOYn-4d7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(recon_x, x, mu, log_var):\n",
        "\n",
        "    recon_loss = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "\n",
        "    kld_loss = -0.0005 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "    return (recon_loss + kld_loss) / x.size(0)\n"
      ],
      "metadata": {
        "id": "YLzSlCQT_KdO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VAE(latent_dim=2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "EPOCHS = 10\n",
        "\n",
        "print(f\"\\n--- Training VAE on {device} ---\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        recon_batch, mu, log_var = model(data)\n",
        "        loss = vae_loss(recon_batch, data, mu, log_var)\n",
        "\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    print(f'====> Epoch: {epoch} Average loss: {avg_loss:.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "id": "T2Ht5x_PAvPj",
        "outputId": "3fda641e-f442-421e-a736-36055b28e3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training VAE on cpu ---\n",
            "====> Epoch: 1 Average loss: 177.6869\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29-3857827792.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_mu = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for data, labels in test_loader:\n",
        "        data = data.to(device)\n",
        "        # We only need mu for this plot\n",
        "        recon, mu, log_var = model(data)\n",
        "        all_mu.append(mu.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "all_mu = torch.cat(all_mu, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(all_mu[:, 0], all_mu[:, 1], c=all_labels, cmap='brg')\n",
        "plt.xlabel('Latent Dim 1 (mu)')\n",
        "plt.ylabel('Latent Dim 2 (mu)')\n",
        "plt.colorbar()\n",
        "plt.title('Test Set Images Mapped to Latent Space')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "oQH9oZv-AyrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 20  # Number of images per side of the grid\n",
        "figure = np.zeros((img_width * n, img_height * n, num_channels))\n",
        "\n",
        "# Create a grid of latent variables\n",
        "grid_x = np.linspace(-5, 5, n)\n",
        "grid_y = np.linspace(-5, 5, n)[::-1]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = torch.tensor([[xi, yi]], device=device, dtype=torch.float32)\n",
        "\n",
        "            # The Keras code uses a separate decoder model. In PyTorch, we can\n",
        "            # just call the relevant parts of our VAE model.\n",
        "            x_decoded_flat = model.decoder_dense(z_sample)\n",
        "            x_decoded = model.decoder_conv(x_decoded_flat)\n",
        "\n",
        "            digit = x_decoded[0].cpu().numpy().reshape(img_height, img_width, num_channels)\n",
        "            figure[i * img_height: (i + 1) * img_height,\n",
        "                   j * img_width: (j + 1) * img_width] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure.squeeze(), cmap='gnuplot2')\n",
        "plt.title('Manifold of Generated Digits from Latent Space')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KeGfWh-jA3w7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}